{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvaluatedModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vyGbh0VuDyc",
        "colab_type": "code",
        "outputId": "3a6ab4b3-b7ea-402f-bbc2-e8c9181147d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "!pip install pytorch-ignite\n",
        "class CnnRegressor(torch.nn.Module):\n",
        "# Define the initialization method\n",
        "  def __init__(self, batch_size, inputs, outputs):\n",
        "# Initialize the superclass and store the parameters\n",
        "    super(CnnRegressor, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs  \n",
        "# Define the input layer\n",
        "# (input channels, output channels, kernel size)\n",
        "    self.input_layer = Conv1d(inputs, batch_size,1)\n",
        "    # Batch normalization\n",
        "    self.input= torch.nn.BatchNorm1d(inputs) \n",
        "# Define a max pooling layer\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "# Define another convolution layer\n",
        "    self.conv_layer = Conv1d(batch_size, 128,1)\n",
        "# Define a max pooling layer\n",
        "    self.max_pooling_layer2 = MaxPool1d(1)\n",
        "    self.flatten_layer = Flatten() \n",
        "# Define a linear layer\n",
        "# (inputs, outputs)\n",
        "    self.linear_layer = Linear(128, 64)   \n",
        "# Finally, define the output layer\n",
        "    self.output_layer = Linear(64, outputs)\n",
        "       \n",
        "# Define a method to feed inputs through the model\n",
        "  def feed(self, input):\n",
        "# Reshape the entry so it can be fed to the input layer\n",
        "# Although weâ€™re using 1D convolution, it still expects a 3D array to process in a 1D fashion\n",
        "    input = input.reshape((self.batch_size, self.inputs, 1))\n",
        "# Get the output of the first layer and run it through the\n",
        "# the ReLU activation function\n",
        "    output = relu(self.input_layer(input))\n",
        "# Get the output of the max pooling layer\n",
        "    output = self.max_pooling_layer(output)\n",
        "# Get the output of the second convolution layer and run it\n",
        "# through the ReLU activation function\n",
        "    output = relu(self.conv_layer(output))\n",
        "# Get the output of the flatten layer\n",
        "    output = self.flatten_layer(output)\n",
        "# Get the output of the linear layer and run it through the\n",
        "# ReLU activation function\n",
        "    output = self.linear_layer(output)\n",
        "# Finally, get the output of the output layer and return it\n",
        "    output = self.output_layer(output)\n",
        "    return output\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PP1P03WVySbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3004cd88-d7a2-44f4-9a39-ca8acf543780"
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = checkpoint['model']\n",
        "    print(model)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    for parameter in model.parameters():\n",
        "        parameter.requires_grad = False\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_checkpoint('1116552_1dconv_reg')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CnnRegressor(\n",
            "  (input_layer): Conv1d(8, 32, kernel_size=(1,), stride=(1,))\n",
            "  (input): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (max_pooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv_layer): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
            "  (max_pooling_layer2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten_layer): Flatten()\n",
            "  (linear_layer): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}